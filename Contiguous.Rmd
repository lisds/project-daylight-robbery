---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# from jupyprint import jupyprint, arraytex

np.set_printoptions(precision=6)
import scipy.stats as sps

from projtools.data import Data

data = Data()
```

# Seasonal Changes Regression Analysis


As can be seen in the previous page, there are some statistically unlikey changes in some crimes based on the time of year. In this section of the notebook we will look into the factors that change with the transition from Greenwich Mean Time (GMT) to British Spring Time (BST).


## Rainfall
It is not unreasonable to assume that the weather influences the prevalence of some crimes, such as theft. It stands to reason that if it is wetter, people will not want to cycle as much. This means there they may be less bikes around for people to steal.

```{python}
rain_dict = {'Months':['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], 'Avg Rainfall (mm)':[58.83, 44.96, 38.78, 42.31, 45.91, 47.25, 45.80, 52.78, 49.61, 65.07, 66.63, 57.05]}
rain_df = pd.DataFrame(data=rain_dict)             
rain_df
```

The dataframe above shows the average rainfall in London per month using data collected from 1991-2020 by the [Met Office](https://metoffice.gov.uk/research/climate/maps-and-data/uk-climate-averages/gcpsvg3nc).

```{python}
rain_df.plot()
plt.ylabel('mm')
plt.xlabel('Month')
```

This data is more easily visualised with the graph above. It seems that rainfall peaks around September and October, with the lowest value in February. According to our hypothesis, this means that some crimes will follow an inverse of this trend.

```{python}
theft = data.borough.loc[:, 'Bicycle Theft', :].T.groupby(level='month').sum().T.sum()
theft_df = theft.to_frame('Bicycle Theft')
theft_df.plot()
plt.ylabel('Recorded Bicycle Thefts')
<<<<<<< Updated upstream
=======
theft_df
>>>>>>> Stashed changes
```

As you can see from the graph above, bicycle thefts peak in July and remain high until October. This does not fit with the hypothesis so far. Now we will do a linear regression to see if there is a correlation between the rainfall and bike thefts or not.

```{python}
rainfall = np.array(rain_df['Avg Rainfall (mm)'])
bike_thefts = np.array(theft_df['Bicycle Theft'])
bike_thefts
```

In our analysis, bike theft will be the outcome variable, while rainfall will be the predictor variable.

`bike_thefts` $ = b $ `rainfall` $+$ $  \text{c} + \vec{\varepsilon} $

To show an strong predictive relationship, we would like the slope (b) to be higher and the error (e) vector to be low.

```{python}
x = rainfall
y = bike_thefts
res = sps.linregress(x, y)
b = res.slope
c = res.intercept
fitted = b * x + c
fitted
errors = y - fitted
errors
```

```{python}
assert np.allclose(y, b * x + c + errors)
b * rainfall + c + errors
```

```{python}
def make_scatter(with_errors = False, show = False):
    plt.scatter(x, y, label='Actual values ($y$)')
    # plot the predicted values
    fitted = b * x + c
    plt.plot(x, fitted, 'ro', label='Fitted values from linear regression ($\hat{y}$)')
    if with_errors == True:
        # plot the distance between predicted and actual, for all points.
        n = len(x)
        for i in range(n):
            plt.plot([x[i], x[i]], [fitted[i], y[i]], 'k:')
        # the following code line is just to trick Matplotlib into making a new
        # a single legend entry for the dotted lines.
        plt.plot([], [], 'k:', label='Errors ($ \\varepsilon $)')
    plt.xlabel('Rainfall')
    plt.ylabel('Bike Thefts')
    # show the legend
    plt.legend();
    if show == True:
        plt.show()
```

```{python}
make_scatter(with_errors = True, show = True)
```

```{python}
make_scatter()
```

```{python}
errors
```
